device_ids: 1
max_epochs: 10
batchsize: 64
flag: 0
check_point_name: 0622_flag${flag}
# === Optimizer Settings ===
Optimizer:
  lr: 2e-4
  eps: 1e-8
  decay: 0.0001

# === Reinforcement Learning Settings ===
discount_factor_gamma: 0.95
min_reward: -0.5
td_loss_coef: 1.0
cql_loss_coef: 1.0

# === Model Architecture ===
qtransformer:
  device: cuda:1
  in_feat_dim: 3
  time_steps: 80
  embed_dim: 256
  num_bins: 28 # 0-7 ball, 8-26 player 27 padding
  num_bins_player: 19
  num_bins_ball: 8
  num_actions: 6         # a0 ~ a5
  max_tokens: 32         # for positional embedding
  decoder_layers: 3
  n_head: 8
  encoder_n_head: 4
  dropout: 0.1

# === EMA Settings ===
ema:
  beta: 0.99
  update_after_step: 10
  update_every: 5


